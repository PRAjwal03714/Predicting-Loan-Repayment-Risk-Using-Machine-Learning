# Predicting-Loan-Repayment-Risk-Using-Machine-Learning
Business Scenario
Financial institutions often reject credit applicants due to limited or non-existent credit history. This project aims to address that by building a predictive model using alternative data such as telco and transactional info, helping lenders assess the likelihood of loan repayment more fairly and effectively.
Our work is inspired by the Home Credit Default Risk Kaggle competition, where the challenge is to predict whether a client will repay a loan or default, based on a massive multi-source dataset.


ğŸ¯ Project Objective
To develop a robust machine learning model that can predict credit default risk by:
â€¢	Handling millions of rows and high-dimensional data
â€¢	Managing missing values and imbalanced classes
â€¢	Performing feature engineering across multiple datasets
â€¢	Training, tuning, and evaluating models using cross-validation
â€¢	Maximizing predictive performance (AUC)


ğŸ‘¥ User Stories
â€¢	Loan Officer: I want a system that accurately predicts credit default risk to improve loan approval decisions.
â€¢	Applicant: I want fairer credit evaluations, even with limited credit history.
â€¢	Data Scientist: I want to use complex, real-world data to solve high-impact financial challenges.


ğŸ§  Methodology Breakdown
ğŸ“˜ Phase 1: Baseline Model Building
â€¢	Explored key tables: application_train, bureau, credit_card_balance, previous_application, etc.
â€¢	Performed data cleaning, missing value handling, and basic preprocessing.
â€¢	Built baseline models using Logistic Regression, with minimal feature engineering.
â€¢	Applied Label Encoding and One-Hot Encoding for categorical variables.
Outcome: Built a working baseline pipeline and achieved initial accuracy scores. Identified areas for improvement like feature extraction and aggregation.


ğŸ› ï¸ Phase 2: Feature Engineering & Data Integration
â€¢	Joined datasets using SK_ID_CURR and SK_ID_PREV keys.
â€¢	Summarized transactional tables using group-by aggregates (e.g., max, mean, min).
â€¢	Created derived features like:
â€“	Payment delay = DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT
â€“	Debt ratio = AMT_CREDIT_SUM_DEBT / AMT_CREDIT_SUM
â€¢	Dealt with imbalanced classes using SMOTE and resampling techniques.
â€¢	Evaluated different models: XGBoost, LightGBM, RandomForest.
Outcome: Enhanced feature richness and significantly boosted model AUC and F1 scores.


ğŸ§ª Phase 3: Final Modeling and Submission
â€¢	Refined final models with:
â€“	Cross-validation using StratifiedKFold
â€“	Grid Search for hyperparameter tuning
â€¢	Built a custom pipeline combining:
â€“	Feature selection (top 50 features)
â€“	Scaling, encoding, and modeling
â€¢	Final model: LightGBM, tuned for best AUC
â€¢	Submitted predictions to Kaggle with consistent results
Outcome: Successfully integrated all phases into a reproducible pipeline with competitive performance on the leaderboard.


âš™ï¸ Technology Stack
Layer	Tools & Libraries
Data Processing	Pandas, NumPy, Scikit-learn
Modeling	LightGBM, XGBoost, RandomForest
Visualization	Seaborn, Matplotlib
Validation	KFold CV, GridSearchCV
Feature Engg.	Aggregates, Ratios, Temporal features


ğŸ“Œ Key Takeaways
â€¢	Efficient handling of large, sparse, and relational datasets
â€¢	Built and optimized a high-performing ML pipeline
â€¢	Improved model interpretability using engineered features
â€¢	Applied real-world credit risk modeling using data science best practices


ğŸ“ˆ Final Impact
â€¢	Learned end-to-end data science workflow
â€¢	Improved AUC from baseline to competitive model
â€¢	Gained practical experience in tackling real financial datasets

